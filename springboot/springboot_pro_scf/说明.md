[toc]

#1.pro_common 公有模块
###1.1 分页结果集
1. @Data   在实体类中用来生成属性的get、set方法
2. @NoArgsConstructor  在实体类中用来生成无参构造方法
3. @AllArgsConstructor 在实体类中用来生成全部参数的构造方法
###1.2 结果集

###1.3 状态码集合类

###1.4 id生成算法(推特雪花算法)

###1.5 结果集工具

#2.pro_base_jpa 基于jpa的基础模块
###2.1 pom文件：  
导入数据库及jpa依赖

###2.2 配置文件application.yml：
1. 指定每个微服务的名称
   ```yaml
   spring:
     application:
       name: base-jpa  #指定服务名
   ```
2. 根据实体自动生成表结构
   ```yaml
   jpa:
       hibernate:
         ddl-auto: update  #根据实体自动生成表结构  
       database-platform: org.hibernate.dialect.MySQL5InnoDBDialect  #不加这句则默认为myisam引擎
   ```
  >可选参数 

      1. create 启动时删数据库中的表，然后创建，退出时不删除数据表 
      2. create-drop 启动时删数据库中的表，然后创建，退出时删除数据表 如果表不存在报错 
      3. update 如果启动时表格式不一致则更新表，原有数据保留 
      4. validate 项目启动表结构进行校验 如果不一致则报错
######此处需注意的是
   1. 数据库引擎需设置为InnoDB，
   2. 数据库的编码格式需和此文件中配置的数据库编码格式一致
###2.3 entity实体类
1. @Entity  jpa 实现映射
2. @Table(name = "tb_label") 对应的表名
3. @DynamicUpdate   对于更新等操作时，时间动态更新
4. @Data
###2.4 controller类
1. @RestController     http请求返回json格式的数据
2. @CrossOrigin        //支持跨域
3. @RequestMapping     请求映射的路径
4. @Autowired          将其他指定bean注入到当前类中
5. @Resource
6. @Autowired 和 @Resource 区别
    @Autowired 默认优先按照类型注入
    @Resource 默认优先按照名称注入
7. RestFul风格：
   1. @RequestMapping("", method=RequestMethod.GET/POST/PUT/DELETE)
   2. @GetMapping 查询所有记录，无条件
      1. @GetMapping(/{参数1}/{参数1})   查询指定参数条件的记录
      ```java
      public class A{
          @GetMapping("/{labelId}")
          public Result findById(@PathVariable("labelId") String id){
              return null;
          }    
      }    
      ```
      #####@PathVariable 路径中的参数与方法参数对应
   3. @PostMapping    保存数据
       ```java
       public class A{
           @PostMapping
           public Result save(@RequestBody Label label){return null;}
       }    
       ```
       #####@RequestBody    请求中的参数为json串转换为指定对象 
   4. @PutMapping     更新数据  
       ```java
       public class A{
            @PutMapping("/{labelId}")
            public Result update(@PathVariable String labelId, @RequestBody Label label){return nu;}
       }     
       ```
   5. @DeleteMapping  删除数据  
        ```java
        public class A{
            @DeleteMapping("/{labelId}")
            public Result delete(@PathVariable String labelId){return null;}
        }    
        ```
   6. 分页
       ```java
       public class A{
           @PostMapping("/search/{page}/{size}")
           public Result searchPage(@RequestBody Label label, @PathVariable int page, @PathVariable int size){
              PageRequest pageRequest = PageRequest.of(page - 1,size);
              Page<Label> pageinfo = labelService.searchPage(label, pageRequest);
              return null;
           } 
       }    
       ```
       #####分页信息包含在路径中page、size

###2.5 Service类
1. @Service     指定组件为service
2. @Transactional    指定组件具有事务控制
3. Specification    基于jpa的复杂条件查询

###2.6 repository类(等价于MyBatis的mapper，传统的DAO层，即持久化)
```java
public interface LabelRepository extends JpaRepository<Label, String>, JpaSpecificationExecutor<Label> {}
```
- 继承JpaRepository，并指定对应类及类的id数据类型；
- 继承JpaSpecificationExecutor接口，并指定对应类，用来实现复杂条件的查询。
- 可根据对应类中的属性定义方法执行查询
- 可自定义方法，添加注解 见[自定义方法](#pro_qa_repository)
###2.7 exception 统一异常处理
@RestControllerAdvice和@ControllerAdvice 

###2.8 config 配置类
@Bean   将指定的类注入到容器中
#3.pro_base_mybatis
待补充
#4.pro_recruit 基于jpa的企业招聘模块
暂无添加

#5.pro_qa    基于jpa的问答模块

<a id="pro_qa_repository"></a>
###5.1 repository类
对于一些特定的操作，无法通过jpa已有方式来生成，则可通过自定义来实现。
```java
public interface B{
     @Query(value = "select * FROM tb_problem, tb_pl WHERE id = problemid AND labelid = ? ORDER BY reply DESC ", nativeQuery = true)
     public Page<Problem> hotlist(String labelid, Pageable pageable);
}     
```
1. @Query   在dao层执行方法
   1. nativeQuery = true 表示可以通过表名来书写sql语句
   2. value的值即为要执行的语句；
   3. ?表示占位符，还可通过另一种方式来实现,注意@Param指定名称和方法参数对应
      ```java
      public interface B{
          @Query(value = "select * FROM tb_problem, tb_pl WHERE id = problemid AND labelid = :labelId ORDER BY reply DESC ", nativeQuery = true)
          public Page<Problem> hotlist(@Param("labelId") String labelid, Pageable pageable);
      }    
      ```
   4. 若为增删改操作，则需添加注解@Modifying
      ```java
      public interface B{
          @Modifying
          @Query(value = "update tb_article SET state = :state WHERE id = :id", nativeQuery = true)
          public void updateState(@Param("state") String state, @Param("id") String id);
      }    
      ```
      

#6.pro_article 基于jpa的文章模块
**添加了缓存功能**
缓存可通过redis、spring-data-redis、spring-cache(默认支持)来实现
本章节通过spring-data-redis来实现
[spring-cache实现缓存](#pro_gathering_cache)
###6.1 pom文件
```xml
<dependencies>
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-data-redis</artifactId>
    </dependency>
</dependencies>
```

###6.2 配置文件(或自定义)默认为application.yml(或properties类型)
```yaml
spring:
    redis:
        host: localhost #等其他redis的相关配置
```
###6.3 Service类
1. 注入redis的操作类RedisTemple或StringRedisTemplate
    ```java
    public class A{
        @Autowired
        private RedisTemplate redisTemplate;
    }    
    ```
    >RedisTemplete对数据结构的操作
    ```java
    public class A {
       private RedisTmplte redisTemplate;
       public void B(){
           redisTemplate.opsForValue();//操作字符串
           redisTemplate.opsForHash();//操作hash
           redisTemplate.opsForList();//操作list
           redisTemplate.opsForSet();//操作set
           redisTemplate.opsForZSet();//操作有序set
       }
    }    
    ```
2. 对于查询方法，在执行查询前先检查缓存中是否有要查询的数据，若没有，才执行数据库查询
    ```java
    public class A {
        public Article findById(String id){
            Article article = (Article) redisTemplate.opsForValue().get("article_" + id);
            if(article == null){
                article = articleRepository.findById(id).get();
                redisTemplate.opsForValue().set("article_" + id, article);
            }
            return article;
        }
    }    
    ```
3. 对于删除或更新操作，则需先删除缓存中的数据，然后在执行操作
    ```java
    public class A{
       public void delete(String id){
            redisTemplate.delete("article_" + id);
            articleRepository.deleteById(id);
       }
    }    
    ```
4. 对于短信验证码过期时间即可通过缓存机制的过期时间来实现

#7.pro_gathering 基于jpa的活动模块
<a id = "pro_gathering_cache"></a>
>默认缓存实现springcache

###7.1 启动类
添加注解@EnableCaching
###7.2 Service类
1. 在查询方法上添加注解@Cacheable(value="", key="#参数")
    1. value属性是必须指定的，其表示当前方法的返回值是会被缓存在哪儿
    2. key是用来指定方法的返回结果时对应的key的。若需要方法的参数来命名，则可通过#来获取
    3. 总体来说就是value指定下的某个键对应的数据即为所要查的数据
2. 在修改或删除的方法上添加注解@CacheEvict(value="", key="#参数")
<a id=pro_mongodb"></a>
#8. pro_spit 基于MongoDB的吐槽模块
[mongodb学习](#mongodb)
###8.1 pom文件
导入依赖
```xml
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-data-mongodb</artifactId>
</dependency>
```

###8.2 配置文件application.yml
```yaml
server:
  port: 8006
spring:
  application:
    name: pro-spit
  data:
    mongodb:
      host: localhost
      database: spitdb
```

###entity8.3 实体
>在MongoDB中主键不能写为id，需写为_id

###8.4 controller控制层
暂无
###8.5 service 业务层
对于涉及某个整型字段的自增操作，实现方式有两种
   ```java
   public class A{
       public void update(int num, String id, String key){
       //        方式一、效率低
       //        Spit spit = spitRepository.findById(id).get();
       //        spit.setThumbup(spit.getThumbup() + num);
       //        spitRepository.save(spit);
       //        方式二、使用MongoDB原生的自增命令来实现
       //        db.spit.update({"_id":"2"},{$inc:{"thumbup": NumberInt(1)}})
           Query query = new Query();
           query.addCriteria(Criteria.where("_id").is(id));
           Update update = new Update();
           update.inc(key, num);
           mongoTemplate.updateFirst(query, update, "spit");
    }
}
   ```
###8.6 repository持久层
```java
public interface SpitRepository extends MongoRepository<Spit, String> {}
```
#9. pro_search 站内搜索模块
###9.1 pom文件
导入依赖
```xml
<dependencies>
    <dependency>
        <groupId>org.springframework.data</groupId>
        <artifactId>spring-data-elasticsearch</artifactId>
        <version>4.0.0.DATAES-628-SNAPSHOT</version>
    </dependency>
</dependencies>  
```

###9.2 配置文件application.yml
```yaml
spring:
  application:
    name: pro-search
  data:
    elasticsearch:
      cluster-nodes: localhost:9300  #服务器地址，java走端口9300
```
###9.3 entity实体 
>与jpa的差别是无需添加Entity和Table，而要添加@Document

```java
/**
* @Document: 文(即相当于mysql的一行记录)
* indexName: 索引库的名称(即相当于mysql的数据库名称)
* type: 类型的名称(即相当于mysql的表名)
*/
@Document(indexName = "pro_db", type = "article")
public class A{
    @Id
    private String id;
    /**
     *  该注解对应数据库的列
     *  index           是否索引，表示该字段(域)是否能被搜索
     *  analyzer        表示存储的时候，按指定的格式分词
     *  searchAnalyzer  表示查询的时候，按指定的格式分词
     */
    @Field(index = true, analyzer = "ik_max_word", searchAnalyzer = "ik_max_word")
    private String title;
}
```

>创建文档的时候，需要考虑的是如下三点
   >1. 是否索引，表示该字段(域)是否能被搜索
   >2. 是否分词，表示搜索的时候是整体匹配还是单词匹配
   >3. 是否存储，表示是否在页面上显示，即文档(该类)中的字段

###9.4 controller控制层
在实际开发中，更多的是执行查询，而对于增删改的操作，是通过**logstash**来数据同步
###9.5 service业务层
在实际开发中，更多的是执行查询，而对于增删改的操作，是通过**logstash**来数据同步
###9.6 repository持久层
继承ElasticsearchRepository即可




<a id="mongodb"></a>
# 框架1. 文档型数据库MongoDB(多应用于大数据)
>关系型：表与表之间有关系
非关系型：表与表之间没有关系

一般情况下，具有以下特点的数据适合使用MongoDB数据库来存储
   >1. 数据量大
   >2. 数据价值低
   >3. 写入操作频繁
##1. 简介
1. 面向文档的非关系型数据库
2. 是最接近关系型的非关系型数据库
3. 支持的数据机构非常松散，类似JSON的BSON格式，因此可存储比较复杂的数据类型

##2. 特点(了解)
   >支持的查询语言非常强大，其语法类似于面向对象的查询语言，是面向集合的、模式自由的文档型数据库

   1. 面向集合存储，易于存储对象类型的数据
   2. 模式自由
   3. 支持动态查询
   4. 支持完全索引，包含内部对象
   5. 支持复制和故障恢复
   6. 使用高效的二进制的形式存储，包括大型对象(如视频等)    
   7. 自动处理碎片，以支持云计算层次的扩展
   8. 支持多种语言的驱动程序
   9. 存储格式为BSON(JSON 的扩展)
##3. 体系结构

    >mongodb 的逻辑结构是一种层次结构，由文档(document)、集合(collection)、数据库(database)三部分组成。
    逻辑结构是面向用户的，用户使用MongoDB开发过程就是使用的逻辑结构。
   1. 文档相当于关系数据库中的一条记录
   2. 多个文档组成一个集合，相当于关系数据库中的一张表
   3. 多个集合逻辑上组合在一起，就是数据库
   4. 一个MongoDB实例支持多个数据库
##4. 数据类型
   >基本数据类型：

   - null:用于表示空值或者不存在的字段，如{"x":null}
   - 布尔值：true和false
   - 数值：默认使用64位浮点型，如{"x":3.14}或{"x": 3},对于整型，可使用NumberInt(4字节)或NumberLong(8字节)，如{"x":NumbreInt("3")}
   - 字符串：utf-8类型的字符都可表示
   - 日期：被存储为自新纪元依赖经过的毫秒数，不包含时区，如{"x":new Date()}
   - 正则表达式：查询时，使用其作为限定条件，语法与JavaScript的相同，如{"x":/[abc]/}
   - 数组: 数组列表或数据集   如{"x":["a","b","c"]}   
   - 内嵌文档：文档可嵌套其他文档，被嵌套的文档作为值来处理，如{"x":{"y":3}}
   - 对象id：对象id是一个12字节的字符串，是文档的唯一标志，如{"x":objectId()}
   - 二进制数据：是任意字节的字符串，不能直接使用，若要讲非utf-8的字符串保存，只能通过二进制的格式
   - 代码：查询和文档中可包含任意js代码，如{"x":function(){/.../}}
##5. 基本命令
   1. 创建数据库
      ```
      use 数据库名
      ```
   2. 插入文档,自动创建了集合
      ```
      数据库名.集合名.insert(数据);
      ```
   3. 查询集合
      ```
      数据库名.集合名.find();
      数据库名.集合名.find({"_id":id值});
      数据库名.集合名.find(bson串);
      ##查询第一条
      数据库名.集合名.findOne(bson串); 
      ##查询指定条件下的前n条记录
      数据库名.集合名.findOne(bson串).limit(n); 
      ##模糊查询，查找name包含伟的记录，注意此处用的是正则表达式
      数据库名.集合名.find({"name":/伟/});
      ```
   4. 修改文档
      ```
      ##注意此方式会将原数据的其他内容删掉，只保留修改的数据
      数据库名.集合名.update(条件, 修改后的数据); db.spit.update({"_id":"1"},{"name":"a"});
      ##注意此方式会将原数据的其他内容保留，只更新所要修改的数据
      数据库名.集合名.update(条件, {$set:修改后的数据}); db.spit.update({"_id":"1"},{$set:{"name":"a"}});
      ```
   5. 删除文档
      ```
      数据库名.集合名.remove(条件); db.spit.remove({_id:"1"});
      ##注意此方式会将所有数据删除
      数据库名.集合名.remove({}); 
      ```
   6. 其他操作
      ```
      ##统计记录条数
      数据库名.集合名.count(); 
      ##统计条件下的记录条数
      数据库名.集合名.count(条件); db.spit.count({"_id":"1"});
      ```
   7. 大于、小于、不等于
      ```
      数据库名.集合名.find({"field" : {$gt : value}}); //大于 field > value
      数据库名.集合名.find({"field" : {$lt : value}}); //小于 field < value
      数据库名.集合名.find({"field" : {$gte : value}}); //大于等于 field >= value
      数据库名.集合名.find({"field" : {$lte : value}}); //小于等于 field <= value
      数据库名.集合名.find({"field" : {$ne : value}}); //不等于 field != value
      ```
   8. 包含、不包含
      ```
      数据库名.集合名.find({"field" : {$in : value}}); //注意value可以是数组
      数据库名.集合名.find({"field" : {$nin : value}}); 
      ```
   9. 条件连接
      ```
      数据库名.集合名.find($and:[{"field" : value},{"field" : value}]); 
      数据库名.集合名.find($or:[{"field" : value},{"field" : value}]); 
      ```
   10. 列值增长
       ```
       数据库名.集合名.update(条件,指定增长);
       #如 表示将id为2的记录的visits的值加1
       db.spit.update({"_id":"2"},{$inc:{"visits": NumberLong(1)}})
       ```
##6. java操作MongoDB
   >mongodb-driver java连接MongoDB的驱动包，类似于jdbc驱动

   **具体实现方式**
   1. 导入依赖
      ```xml
      <dependency>
          <groupId>org.mongodb</groupId>
          <artifactId>mongodb-driver</artifactId>
      </dependency>
      ```
   2. 操作
      ```java
      public class A{
          public static void main(String[] args) {
               //连接MongoDB服务器,默认端口为27017
               MongoClient client = new MongoClient("localhost");
               //得到要操作的数据库
               MongoDatabase database = client.getDatabase("databaseName");
               //得到要操作的集合
               MongoCollection<Document> collectonName = database.getCollection("collectonName");
               //得到集合中的所有文档
               FindIterable<Document> documents = collectonName.find();
               //遍历数据
               for (Document doc : documents){
                   System.out.println(doc);
               }
               client.close();
           } 
      }    
      ```
##7. SpringDataMongoDB在springboot中的应用
[SpringDataMongoDB在springboot中的应用](#pro_mongodb)


单点登录：无状态(服务端是否存储登录信息)的jwt

# 框架2. 分布式搜索引擎ElasticSearch

### 1. 简介

1. 一个**实时的分布式**搜索和分析引擎
2. 快速处理大规模的数据
3. 是一个基于Lucene的搜索服务器，基于RESTful web 的接口
4. 与Solr最大的区别是Solr本身不能做分布式，若要做，需要借助额外的插件来实现



### 2. 特点

1. 可作为大型分布式集群(数百台服务器)，处理PB级数据
2. 将全文检索、数据分析和分布式合并到一起
3. 开箱即用(解压就可以使用)，部署简单
4. 全文检索、同义词处理、相关度排名、复杂数据分析，海量数据的接近实时处理 



### 3. 体系结构(逻辑结构)

>ElasticSearch(ES)和MySQL的逻辑结构的类比
1. ES中的文档(document) 等价于mysql中的行记录(row);
2. ES中的类型(type) 等价于mysql中的表结构(table)
3. ES中的索引(index) 等价于mysql中的数据库(databases)

| elasticsearch | mysql | mongodb  |
|--------|--------|--------|
| 索引(index) | 数据库(databases) | 数据库(databases) |
| 类型(type)  | 表结构(table)| 集合(collection) |
| 文档(document)  | 行记录(row)| 文档(document) |
| 域(Field)  | 列(col) |---- |

### 4. ES安装

>找到安装包，解压到指定位置，配置环境变量，即可使用
1. 在命令行窗口中，执行elasticsearch命令即可启动，
2. 若未配置环境变量，需切换到安装路径的bin目录下执行即可
3. 默认两个端口9300，,9200；java开发使用9300端口，其他语言使用9200 http

4. 启动成功后，可在网页端通过http://localhost:9300访问，返回json串，其他操作见[操作](#es_opoerate)
   

### 5. 调用RestAPI完成基本增删改查操作<a id="es_operate"></a>

1. 创建索引库，直接发起请求
   ```html
   <!-- put方式请求 --> 
   http://localhost:9300/索引库名
   ```
   
2. 新建文档   
   ```html
   <!--post方式请求 --> 
   http://localhost:9300/索引库名/类型名
   <!-- #文档内容可通过请求的body来携带，即在body中添加json串 --> 
   {"":""}
   <!-- 创建后的结果集中的：版本号version会加1，created:true,result:created,_id为生成的文档id  --> 
   ```
   
3. 查询
   ```html
   <!--get方式请求 --> 
   #查询所有
   http://localhost:9300/索引库名/类型名/_search
   <!-- 查询指定id --> 
   http://localhost:9300/索引库名/类型名/文档id
   <!-- 条件查询，支持模糊查询，此处的分词器为默认的，分词的词条最小单位是一个汉字或一个单词。不是IK分词器 --> 
   http://localhost:9300/索引库名/类型名/_search?q=content:你好
   http://localhost:9300/索引库名/类型名/_search?q=content:*s*
   ```
   
4. 更新
   ```html
   <!-- put方式请求
   #注意此处的文档id若存在，则为更新，若不存在，则为新增 --> 
   http://localhost:9300/索引库名/类型名/文档id
   <!-- 文档内容可通过请求的body来携带，即在body中添加json串 --> 
   {"":""}
   <!--更新后的结果集中的：版本号version会加1，created:false,result:updated --> 
   ```
   
5. 删除
   ```html
   <!-- delete方式请求 --> 
   http://localhost:9300/索引库名/类型名/文档id
   ```
###6. Head插件(操作ES的图形化界面)的基本使用
   
1. 安装head插件
   1. 下载包，解压到指定目录
   2. 安装node.js，命令行窗口执行如下命令安装cnpm
      ```
      npm install -g cnpm --registry=http://registry.npm.taobao.org
      ```
   3. 命令行窗口执行如下命令，将grunt命令安装为全局命令，grunt是基于Node.js的项目构建工具
      ```
      npm install -g grunt-cli
      ```
   4. 命令行窗口下，将路径跳转到head解压路径，然后执行如下命令，安装依赖  
      ```
      cnpm install
      ```
   5. 命令行窗口下进入head目录，执行如下命令  
      ```
      grunt server
      ```
   6. 访问http://localhost:9100即可  
   >注意此时无法连接，是因为暂时还不支持跨域，若要支持，需修改es的配置文件
   修改方式为在elasticsearch.yml文件中添加如下代码
      ```yaml
      http.cors.enabled: true   
      http.cors.allow-origin: "*"
      ```
   
2. 使用      
   
### 7. IK分词器
1. 简介
   >启动elasticsearch后，浏览器输入如下网址，初步了解分词器
   ```html
   <!-- _analyze:表示分词器，analyzer=chinese 指定用哪个分词器， pretty=true 表示要分词-->
   http://localhost:9200/_analyze?analyzer=chinese&pretty=true&text=我是程序员
   ```
   >默认的中文分词器是将每个字看成一个词，这不符合实际使用，所以引入中文分词器来解决。
2. 安装
   >1. 下载包，解压并命名为ik
   >2. 将ik文件夹放在elasticsearch安装路径下的plugins目录下
   >3. 重新启动es，再次访问则使用了ik分词
3. 测试
   >1. IK分词器提供了两个分词算法ik_smart和ik_max_word
   >2. ik_smart为最少切分，即将要切分的语句切分最少次
   >3. ik_max_word为最细粒度切分
4. 自定义词库
>对于一些特定的词汇，我们不希望被切分，可自定义词条
   >1. 进入es目录下的plugins/ik/config目录
   >2. 新建一个dic的文件，编辑特定的词汇到文件中，注意该文件需保存为无bom的utf-8格式
   >3. 修改该目录下的IKAnalyzer.cfg.xml文件
   ```xml
   <properties>
     <comment>扩展配置</comment>
     <!-- 在这里配置扩展的字典 -->
     <entry key="ext_dict">新建的dic文件全称</entry>
     <!-- 在这里配置扩展停止词字典 -->
     <entry key="ext_stopwords">dic文件全称</entry>
   </properties>
   ```

###7. es与mysql数据同步
####7.1 logstash
1. 简介
   >是一款轻量级的日志搜集处理框架，可以把分散的、多样化的日志搜集起来，
   进行自定义的处理，然后传输到指定的位置，如某个服务器或文件等。
   
2. 安装与测试
   >1. 下载包，解压到指定位置
   >2. 命令行窗口切换到安装包下的bin目录，执行如下命令
      ```html
      <!-- -e 表示后面直接写命令
           -f 表示命令过长，指定一个文件路径 -->
      logstash -e 命令 
      如 logstash -e 'input { stdin{ } } output { stdout { } }'  
         表示从控制台输入值，在控制台输出值，stdin 表示输入流，键盘录入，stdout 输出流 显示器输出
      logstash -f 文件路径(文件格式为*.conf)
      ```
3. 操作
   >1. 将模板文件(*.conf)和数据库的驱动放在指定位置(如：a)，一般放在logstash安装目录下新建一个文件夹
   >2. 模板文件的内容格式如下，可从网络查找修改
   ```
   input {
      jdbc {
          #数据库连接的url
          jdbc-connection_string => ""
          #用户名和密码
          jdbc_user => ""
          jdbc_password => ""
          # 数据库驱动的位置(全路径)
          jdbc_driver_library => ""
          # 数据库驱动类
          jabc_driver_class => ""
          # 是否分页
          jdbc_paging_enabled => ""
          jdbc_paging_size => ""
          # 对应要执行的sql的绝对路径，以下两个只能使用其中一个
          statement_filepath => ""
          statement => ""
          #定时执行， 各字段的含义(左至右)：分->时->天->月->年，全部为*默认，含义是每分钟都更新
          schedule => "* * * * *"
      } 
   }
   output {
      elasticsearch {
          #es ip 地址和接口
          hosts => ""
          #es 索引名称
          index => ""
          #id编号
          document_id => "%{id}"
          document_type => ""
      }
      stdout {
          #json格式输出
          codec => json_lines
      }
   } 
   ```
需注意，索引库中的数据无法删除，所以一般情况下删除数据库的数据要逻辑删除，不能物理删除。

###8. 在虚拟机中docker中安装
####1. 下载镜像
```linux
docker pull es 镜像
```
####2. 启动容器
```linux
docker run -di --name=es -p 9200:9200 -p 9300:9300 镜像名:版本
```
>此时，通过网页访问，无法访问，查看后es默认内存配置为2G，内存不足以分配导致,所以需要将其修改

解决方法就是修改jvm空间分配
1. 运行命令：    
    ```linux
    find /var/lib/docker/overlay/ -name jvm.options #若提示没有该目录，则执行
    find /var/lib/docker -name jvm.options
    ```
2. 找jvm.options文件，找到后进入使用vi命令打开jvm.options
    将    
    ```text
    -Xms2g
    -Xmx2g
    ```
    修改为
    ```text
    -Xms512m  
    -Xmx512
    ```
3. 保存退出即可。再次运行创建elasticsearch容器命令，成功启动    


# 框架3. RabbitMQ 消息队列

### 1. 简介
>消息中间件是分布式系统的重要组成部分
   >1. 主要解决应用耦合、异步消息、流量削峰等问题
   >2. 实现高性能、高可用、可伸缩和最终一致性

   #####activeMQ raabbitMQ kafka三者速度依次加快，安全性依次降低，kafka多应用于大数据。

### 2. 应用场景
   >1. 异步处理
   >2. 应用解耦
   >3. 流量削峰
   >4. 消息通讯
### 3. 安装
   >1. 下载两个安装包，安装后，切换到安装目录下的sbin目录
   >2. 安装管理界面，打开命令行窗口切换到sbin目录，执行如下命令
      ```
      rabbitmq-plugins enable rabbitmq_management
      ```
   >3. 打开浏览器输入网址http://localhost:15672,即可看到管理界面，
   用户名和密码分别是guest   
### 4. 虚拟机docker安装
>注意有5个端口，5671,5672，4369，15671,15672，25672,其中
   15672端口为rabbitmq前端管理界面的接口，5672为应用接口，其他接口为内部接口。

>1. docker search rabbitmq
>2. docker pull xxx
>3. docker run -di --name=xxx -p 5671:5671 -p 5672:5672 -p 4369:4369
    -p 15671:15671 -p 15672:15672 -p 25672:25672 镜像名：版本



# 框架4. 基于JWT的token认证机制 
### 1. 常见的认证(登录)机制
##### 1. Http Basic Auth
>简单说就是每次请求API时，都提供用户的username和password，即Basic Auth是
配合RESTful API使用的最简单的认证方式，只需提供用户名和密码即可，但存在把用
户名和密码暴露给第三方客户端的风险，因此，使用较少。

> 缺点：效率低
> 优点：无状态(服务器端无需存储登录信息)

##### 2. Cookie Auth
>Cookie认证机制就是为一次请求认证在服务端创建一个Session对象，同时在客户端
浏览器创建创建一个Cookie对象，通过客户端带上cookie对象与服务器端的Session
对象匹配来实现状态管理。

>Cookie 不安全，容易csrf攻击
>有状态的

##### 3. OAuth(开放授权)   
是一个开放授权的标准，允许用户让第三方应用访问该用户在某一web服务上存储的私密
资源，而无需用户名和密码。
##### 4. Token Auth(令牌认证) -》相当于尚方宝剑     
1. 大概流程为：
   >1. 客户端使用用户名和密码请求登录
   >2. 服务端收到请求，去验证用户名和密码
   >3. 验证成功后，服务端会签发一个Token，然后将token发给客户端
   >4. 客户端收到token后将其存储起来，如cookie
   >5. 之后客户端再次发起请求时将token携带
   >6. 服务端收到请求，先去验证请求中携带的token，若验证成功，返回请求内容
2. 优点(相对于cookie)
   >1. 支持跨域访问，cookie不支持
   >2. 无状态：Token机制在服务端无需存储session信息，因为自身包含了
   用户登录的所有信息   
   >3. 更适用CDN，适用于移动端
   >4. 去耦:无需绑定到特定的身份验证方案，token可在任何地方生成，只要在api被
   调用的时候，生成token调用即可。 

### 2. 基于JWT的token认证机制 
>JWT:JSON Web Token是一个轻巧的规范，允许我们使用jwt在用户和服务器之间传递安全可靠的信息

##### 1.JWT组成
>一个JWT实际上就是一个字符串，由三部分组成，分别是头部、载荷与签名。
1. 头部(Header)
   >用户描述该JWT的基本信息，例如其类型、签名所用算法等。可以通过一个json对象表示
   ```json
   {"typ":"JWT","alg":"HS256"}
   ```
   最后对其进行Base64(JWT默认编码格式)编码为一串字符

2. 载荷(playload)
   >存放有效信息的地方，有效信息包含三部分，分别是
      >1. 标准中注册的声明(都非必须)
         ```
         iss: jwt签发者
         sub: jwt所面向的用户,即登录的用户名
         aud: 接收jwt的一方
         exp: jwt的过期时间，需大于签发时间
         nbf: 定义在什么时间之前，该jwt是不可用的
         iat: jwt签发时间
         jti: jwt的唯一身份标识，用来作为一次性token
         ```
      >2. 公共的声明
      >3. 私有的声明
   
    如：
    ```json
    {"sub":"123456","name":"jhon","admin":true}
    ```
   最后对其进行Base64(JWT默认编码格式)编码为一串字符  

3. 签证(signature)
签证由三部分组成
   >头部(Header)->BASE64后的
   >载荷(playload)->BASE64后的   
   >secret(盐)   

该部分需要BASE64加密后的Header和BASE64加密后的playload通过.连接组成的字符串，
然后通过header中声明的加密方式进行加盐(secret)组合加密构成jwt的第三部分。

将这三部分通过.连接构成的字符串即为最终的jwt
注意部分：
   >1. secret 是保存在服务器端的，
   >2. jwt的签发生成也是在服务器端的
   >3. secret 就是用来签发和验证jwt的，所以，是服务端的私钥，不能暴露

### 3. JAVA的JJWT实现JWT

##### 1.token创建
1.pom引入依赖
##### 2.token 解析
参考:[JWT解析](https://www.jianshu.com/p/6bfeb86885a3)
    [JWT生成token及过期处理方案](https://my.oschina.net/odetteisgorgeous/blog/1920762)
>注意这几个方法的区别
>1. parsePlaintextJwt 载荷为文本（不是Json），未签名
>2. parseClaimsJwt 载荷为claims（即Json），未签名
3. parsePlaintextJws 载荷为文本（不是Json），已签名
>4. parseClaimsJws 载荷为claims（即Json），已签名


# 框架5. Spring Cloud
### 0. 基础介绍
##### 1. 简介
>是一系列框架的有序集合，利用springboot的开发便利性(默认优于配置)简化了
分布式系统开发。
   >1. 服务发现注册
   >2. 配置中心
   >3. 消息总线
   >4. 负载均衡
   >5. 熔断器
   >6. 数据监控
   >7. 等等
##### 2. 与springboot的关系
   >1. springboot 专注于快速高效的开发单个微服务
   >2. springcloud 关注全局的服务治理
   >3. springboot 可以离开springcloud单独开发
   >4. springcloud 离不开springboot，属于依赖关系
   >5. **springboot 开发版本需和springcloud版本对应**
##### 3. 主要框架
   >1. 服务发现：Eureka
   >2. 服务调用：Feign
   >3. 熔断器： Hystrix
   >4. 服务网关： Zuul
   >5. 分布式配置： Spring Cloud Config
   >6. 消息总线： Spring Cloud Bus
##### 4. 与dubbo的对比
dubbo相当于spring cloud的子集

### 1. Eureka 服务发现
>1. 类似于dubbo 和 zokeerper
>2. 包含两个组件：Eureka Server和Eureka Client
#### 1. Eureka Server
>提供服务注册服务，各个节点服务启动后，会在Eureka Server中注册，则server会在服务注册表中
存储所有可用服务节点的信息，这些信息会在管理界面中看到。

即一个微服务想让其他服务发现，就要让自己成为Eureka Client(客户端)，即注册到服务端。

#### 2. Eureka Client
>是一个java客户端，用于简化和server的交互。

客户端应用启动后，会定时向服务端发送一个心跳(默认周期为30秒)，若server端在多个心跳周期内没有发现某个
节点(客户端)的心跳，则服务端会从服务注册表中将该节点(客户端)移除(默认为90秒)。

#### 3. Eureka Server开发
##### 1. 在父工程中pom中添加版本锁定
   ```xml
   <dependencyManagement>
       <dependencies>
           <dependency>
               <groupId>org.springframework.cloud</groupId>
               <artifactId>spring-cloud-dependencies</artifactId>
               <version>Greenwich.SR1</version>
               <type>pom</type>
               <scope>import</scope>
           </dependency>
       </dependencies>
   </dependencyManagement>
   ```
   需注意springboot版本和springcloud版本对应，否则会报错
   参考[版本对应](https://spring.io/projects/spring-cloud#overview)

##### 2. 新建模块作为服务发现的服务端
1. pom 添加依赖
   ```xml
   <dependencies>
       <dependency>
           <groupId>org.springframework.cloud</groupId>
           <artifactId>spring-cloud-starter-netflix-eureka-server</artifactId>
       </dependency>
   </dependencies>
   ```
2. 配置文件配置
   ```yaml
   server:
     port: 8099
   eureka:
     client:
       register-with-eureka: false   #是否把当前模块注册到服务器中，本身就是服务器，所以为false
       fetch-registry: false     #是否从Eureka中获取注册信息
       service-url:    #Eureka客户端与服务端交互的地址
         defaultZone: http://localhost:${server.port}/eureka/
   ```
3. 创建启动类
   
   >添加注解@EnableEurekaServer
#### 4. Eureka Client开发
1. 在已开发模块中添加依赖
   ```xml
   <dependency>
       <groupId>org.springframework.cloud</groupId>
       <artifactId>spring-cloud-starter-netflix-eureka-client</artifactId>
   </dependency>
   ```
2. 修改配置文件
3. 启动类
   
   >添加注解@EnableEurekaClient

### 2. Feign 实现服务间的调用
>前提是先能发现服务才可调用
#### 1. 先搞清逻辑，A模块调用B模块，则操作A模块
1. pom文件导入依赖
   ```xml
   <dependency>
       <groupId>org.springframework.cloud</groupId>
       <artifactId>spring-cloud-starter-openfeign</artifactId>
   </dependency>
   ```
2. 创建要调用模块(B模块)的客户端接口
   ```java
   @FeignClient("base-jpa")  //FeignClient用于指定从哪个服务调用功能
   public interface BaseJpaClient {
    //将需要的方法声明到该接口中
      @GetMapping("/label/{labelId}")
       public Result findById(@PathVariable("labelId") String labelId);
   }
   ```
3. 启动类添加注解
   >1. @EnableDiscoveryClient
   >2. @EnableFeignClients   //采用Feign的方式去发现

4. 调用
如：在controller中调用
   ```java
   public class A{
       @Autowired
       private BaseJpaClient baseJpaClient;
       @GetMapping("/label/{labelId}")
       public Result findByLabelId(@PathVariable String labelId){
           return baseJpaClient.findById(labelId);
       }
    }
   ```
5. 默认支持负载均衡
   
### 3. 熔断器(Hystrix) 
雪崩效应
>使得系统再出现依赖服务失效的时候，通过隔离系统所依赖的服务，防止服务级联失败，
>同时提供失败回退机制，更好的应对失效
>
>1. feign本身就支持hystrix，所以无需再引入依赖
#### 1.使用
1. 针对调用的其他服务客户端(client),创建实现类
2. 在客户端(client)上的注解@FeignClient中添加信息如下
   ```java
   @FeignClient(value = "base-jpa", fallback = BaseJpaClientImpl.class)
   public interface BaseJpaClient{} 
   ```
3. 在配置文件中添加
   ```yaml
   feign:
     hystrix:
       enabled: true     #打开熔断器
   ```
>当依赖的服务断掉后，调用该服务的方法会走指定的返回类(即fallback指定的类),当
依赖的服务重新连接上后，调用该服务则继续该有的执行，而不会走fallback。
### 3. 路由网关 Zuul

#### 1. 提出问题
>1. 不同的微服务有不同的网络地址，外部的客户端可能需要调用多个服务的接口才能实现功能，
>2. 若客户端直接和微服务通信，则会出现如下问题
    1. 客户端会多次请求不同微服务，增加了客户端的复杂性
    2. 存在跨域请求，在一定场景下处理增加了复杂性
    3. 认证复杂，每一个服务都需要独立认证

#### 2. 项目应用 路由转发
1. pom文件导入依赖
   ```xml
   <dependencies>
   <dependency>
       <groupId>org.springframework.cloud</groupId>
       <artifactId>spring-cloud-starter-netflix-eureka-client</artifactId>
   </dependency>
   <dependency>
       <groupId>org.springframework.cloud</groupId>
       <artifactId>spring-cloud-starter-netflix-zuul</artifactId>
   </dependency>
   </dependencies>
   ```
2. 配置文件
   ```yaml
   server:
     port: 8092
   spring:
     application:
       name: pro-web
   eureka:
     client:
       service-url:    #Eureka客户端与服务端交互的地址
         defaultZone: http://localhost:8099/eureka/
     instance:
       prefer-ip-address: true     #模块之间支持跨域
   zuul:
     routes:       #指定微服务及访问的路径跳转到的模块
       pro-base:         #指定微服务
         path: /base/**  #指定微服务的访问路径
         serviceId: pro-base   #上面指定的路径则跳转到该模块，即指定Eureka注册中心的服务id
   ```
3. 创建启动类
   ```java
   @SpringBootApplication
   @EnableEurekaClient
   @EnableZuulProxy
   public class WebApplication {}
   ```
#### 3. 网关过滤器
    参考pro_manager的ManagerFilter类

### 4.集中配置组件SpringCloud Config
>1. config server
>2. config client
![框架图](/images/springcloud_config%20框架结构.png)

#### 1.config server
>用于集中管理应用程序各个模块下的配置
1. 将各模块的配置文件通过A-B的方式命名，然后统一到git或svn等平台管理，并将地址留用
   >1. 文件命名规范：{application}-{profile}.yml或{application}-{profile}.properties
   >2. application为应用名称，profile为开发环境，如开发，测试，生产等
2. 在项目中创建配置中心微服务模块
   1. pom导入依赖
       ```xml
       <dependency>
           <groupId>org.springframework.cloud</groupId>
           <artifactId>spring-cloud-config-server</artifactId>
       </dependency>
       ```
   2. 配置文件
      ```yaml
      server:
        port: 9080
      spring:
        application:
          name: pro-web
        cloud:
          config:
            server:
              git:
                uri: https://gitee.com/git账号/项目名.git   #配置文件存放git的访问路径
                #username:
                #password:
                searchPaths: config-repo #仓库相对路径
      ```
   3. 启动类
      ```java
      @SpringBootApplication
      @EnableConfigServer
      public class ConfigApplication {}
      ```
   4. 测试访问获取
      
      >访问http://localhost:9080/git中的文件名
#### 2.config client
1. 在某个模块中应用
   1. 将该模块的配置文件放在git中,模块中删除该文件
   2. 在pom文件中添加依赖
      ```xml
      <dependency>
          <groupId>org.springframework.cloud</groupId>
          <artifactId>spring-cloud-starter-config</artifactId>
      </dependency>
      ```
   3. 添加一个配置文件bootstrap.yml，配置连接config服务的信息
      >1. bootstrap的优先级高于application
      >2. 一般情况下bootstrap.yml中配置的信息为系统级信息，application中配置的应用级信息
      ```yaml
      spring:
        cloud:
          config:
            name: base    #git中该微服务的配置文件的名称前缀
            profile: dev  #git中该微服务的配置文件的名称后缀
            label: master   # git主干
            uri: http://localhost:9080 #指定配置服务的访问路径
      ```

### 5.消息总件 Bus
>在微服务模块中添加一个监听，监听配置文件是否改变，若改变，重新获取配置文件，并编译项目
![框架图](/images/springcloud_bus%20框架结构.png)

#### 1.简介


#### 2. 应用
##### 1. 服务端
在配置中心微服务模块中做如下操作
1. pom文件添加依赖
   ```xml
   <dependencies>
   <dependency>
       <groupId>org.springframework.cloud</groupId>
       <artifactId>spring-cloud-bus</artifactId>
   </dependency>
   <dependency>
       <groupId>org.springframework.cloud</groupId>
       <artifactId>spring-cloud-stream-binder-rabbit</artifactId>
   </dependency>
   </dependencies>
   ```
2. 配置文件application.xml
   ```yaml
   spring:
     rabbitmq:
       host: localhost   #bus需要消息队列
   management:   #暴露触发消息总线的地址
     endpoints:
       web:
         exposure:
           include: bus-refresh
   ```
##### 2. 客户端
1. pom引入依赖
   ```xml
   <dependencies>
   <dependency>
       <groupId>org.springframework.cloud</groupId>
       <artifactId>spring-cloud-bus</artifactId>
   </dependency>
   <dependency>
       <groupId>org.springframework.cloud</groupId>
       <artifactId>spring-cloud-stream-binder-rabbit</artifactId>
   </dependency>
   <dependency><!-- 监听 -->
     <groupId>org.springframework.boot</groupId>
     <artifactId>spring-boot-starter-actuator</artifactId>
   </dependency> 
   </dependencies>
   ```
2. 配置文件(上传到git的文件)添加配置
   ```yaml
   spring:
      rabbitmq:
         host: localhost   #bus需要消息队列
   ```
3. 测试
   >1. 启动Eureka、config(上面的服务端)及配置了bus的客户端
   >2. 访问客户端的某个请求
   >3. 修改git中该客户端的配置文件
   >4. 以post的方式访问http://localhost:9080/actuator/bus-refresh，相当于发送一条消息到消息队列，注意该路径为配置中心服务模块的路径
   >5. 此时监听器监听到消息队列有消息，会重新获取配置文件并编译项目
   >6. 再次访问客户端的某个请求，会发现配置修改后
4. 自定义配置
>当某个模块中的配置文件中有自定义的配置文件，此时更新了配置文件中自定义属性的值后，再次访问值不会改变，
若想使其随着配置文件改变而改变，可以在controller上添加注解@RefreshScope

### 6.微服务容器部署和持续集成jenkins
所有操作需有前提，1已有Linux服务器，且安装了docker，若想本地操作，可安装xshell等远程操作工具
#### 1.Dockerfile(手动发布镜像)
##### 1. 简介
>1. 是由一系列命令和参数构成的脚本。能够把本地的代码发布到服务器成一个镜像的形式。
>2. 这些命令应用于基础镜像并最终创建一个新的镜像
##### 2. 作用
>1. 对于开发人员：为开发团队提供完全一致的开发环境
>2. 对于测试人员：通过dockerfile文件可以直接创建一个新的镜像来工作
>3. 对于运维人员：在部署时，可以实现应用的无缝移植
##### 3. 常用命令
image:镜像，tag：版本号
>1. FROM image_name：tag ->表示当前要制作的镜像依赖于tag版本的image_name(镜像名称)
>2. MAINTAINER user_name     ->声明镜像的创建者
>3. ENV key value   ->设置环境变量(键值对)，可以有多条
>4. RUN command     ->是Dockerfile的核心部分，执行指定命令，可以有多条
>5. ADD source_dir/file_dest_dir/file   ->将宿主机(本地电脑)的文件复制到容器内，若是压缩文件，会复制后自动解压
>6. COPY source_dir/file_dest_dir/file   ->将宿主机(本地电脑)的文件复制到容器内，若是压缩文件，会只复制不解压
>7. WORKDIR path_dir    ->设置工作目录
>8. EXPOSE port1 port2  ->指定端口号，使容器内的应用可通过端口和外界交互
>9. CMD argument    ->在构建容器时使用，会被docker run后的argument覆盖
>10. ENTRYPOINT argument    ->在构建容器时使用，不会被docker run后的argument覆盖
##### 4. 使用脚本创建镜像
**以创建JDK 镜像为例**
1. 创建目录(在xshell中或直接在服务器上Linux下)
   ```text
   mkdir -p /usr/local/docker_jdk8
   ```
   也可用xftp图形化界面直接创建文件
2. 下载jdk8.tar.gz并上传到中的上面目录中
3. 创建文件Dockerfile
   >1. 该文件必须与第2步中的文件在同一目录下
   >2. 该文件名称必须为Dockerfile
4. 文件内容(示例)
   ```properties
   #依赖镜像名称和id(版本)
   FROM centos:7
   #声明创建者
   MAINTAINER bj
   #切换工作目录
   WORKDIR /usr
   #运行命令 创建目录
   RUN mkdir /usr/local/java
   #注意ADD后的文件是相对路径
   ADD jdk8.tag.gz /usr/local/java/
   #设置环境变量
   ENV JAVA_HOME /usr/local/java/jdk8
   ENV JRE_HOME $JAVA_HOME/jre
   ENV CLASSPATH $JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tool.jar:$JRE_HOME/lib:$CLASSPATH
   ENV PATH $JAVA_HOME/bin:$PATH
   ```
5. 切换目录到第一步创建的目录下
`cd /usr/local/docker_jdk8`
6. 执行如下命令构建镜像
   ```text
   docker build -t = 'jdk1.8' .
   ```
   >上面的命令表示构建一个叫jdk1.8的镜像在当前目录下，注意最后的空格和点表示当前目录
7. 执行命令查看创建的镜像
   ```text
   docker images
   ```
8. 创建容器(先到根目录然后执行如下命令)
   ```text
   docker run -id --name = myjdk8 jdk1.8
   ```
   >1. --name 表示为容器指定名称
   >2. jdk1.8 指定要创建容器的镜像是哪个，若有多个版本的镜像，可通过 镜像:版本号的方式来指定
9. 查看已创建的容器
   ```text
   docker ps
   ```
#### 2. 私有仓库
是指对于一个应用可能在多处需要使用，每次使用都需要构建镜像，创建容器，通过私有仓库，
可以一次构建镜像将其放入私有仓库，需要使用的时候，直接下载镜像，创建容器即可，而无需再次构建。
##### 1. 私有仓库搭建与配置
1. 获取私有仓库的镜像
   ```text
   docker pull registry
   ```
2. 启动私有仓库容器
   ```text
   docker run -di --name=registry -p 5000:5000 registry
   ```
   >1. 打开浏览器 输入地址 http://ip地址:5000/v2/_catalog,此处的ip地址为服务器的ip地址
   >2. 浏览器可看到{"repositories":[]},表示私有仓库搭建成功并且内容为空。
3. 修改 daemon.json
   ```text
   vim /etc/docker/daemon.json
   ```
   >添加内容{"insecure-registries":["ip地址:5000"]}，用于让 docker信任私有仓库地址
   
   **注意：**
   看该文件是否修改镜像下载地址，默认国外地址下载较慢，可修改为如下国内地址(或其他)
   ```text
   {"registry-mirrors":["https:docker.mirrors.ustc.edu.cn"]}
   ```
   该文件只有一个大括号，多个内容通过逗号分隔
4. 重启docker
   ```text
   systemctl daemon-reload
   systemctl restart docker
   ```
##### 2.上传镜像到私有仓库
1. 先启动私有仓库
   ```text
   #查看已有容器
   docker ps -a
   #启动私有仓库的容器
   docker start 仓库容器名
   ```
2. 查看已有镜像或者下载所需镜像
   ```text
   #查看已有镜像
   docker images
   #下载所需镜像
   docker pull 镜像名
   ```
3. 修改标记Tag，即标记此镜像为私有仓库中的镜像 
   ```text
   docker tag 镜像 服务端ip地址:5000/私有仓库中该镜像的名称
   ```
   >此时通过docker images查看镜像会发现有两个该镜像，一个是原有的，一个是标记后的镜像
4. 上传镜像到私有仓库
   ```text
   docker push 服务端ip地址:5000/私有仓库中该镜像的名称
   ```
5. 查看私有仓库
   通过浏览器查看 http://服务端ip地址:5000/v2/_catalog 可以看到刚上传的镜像

#### 3. DockerMaven插件
##### 1.微服务部署的方式
>1. 手动部署：先基于源码打包生成jar(或war)包，将包上传至虚拟机并拷贝到jdk容器
>2. 通过maven插件自动部署

##### 2.Maven 自动部署的步骤
1. 修改宿主机的Docker配置，让其可以远程访问
   ```text
   vi /lib/systemd/system/docker.service
   ```
   >其中ExecStart后面添加-H tcp://0.0.0.0:2375 -H unix:///var/run/docker.sock
2. 重启docker和私有仓库
3. 在项目模块中操作
   1. pom文件导入插件
      ```xml
      <build>
          <!-- 当前工程的名称 -->
          <finalName>config</finalName>
          <plugins>
              <plugin>
                  <groupId>org.springframework.boot</groupId>
                  <artifactId>spring-boot-maven-plugin</artifactId>
              </plugin>
              <plugin>
                  <groupId>org.springframework.boot</groupId>
                  <artifactId>docker-maven-plugin</artifactId>
                  <configuration>
                      <!-- 镜像的名称标记 -->
                      <imageName>服务器ip地址:5000/${project.artifactId}/${project.version}</imageName>
                      <!-- 基础镜像 -->
                      <baseImage>jdk1.8</baseImage>
                      <!-- 进入后执行java -jar *.jar 打包命令 -->
                      <entryPoint>["java", "-jar", "/{project.build.finalName}.jar"]</entryPoint>
                      <resources>
                          <resource>
                              <targetPath>/</targetPath>
                              <directory>${project.build.directory}</directory>
                              <include>${project.build.finalName}</include>
                          </resource>
                      </resources>
                      <dockerHost>http://服务器ip:2375</dockerHost>
                  </configuration>
              </plugin>
          </plugins>
      </build>
      ```
   2. 确保该项目模块所需的依赖都已启动，如rabbitmq等 
   3. 在idea打开Terminal视图，在project中选中模块，拖到Terminal视图
      
      >**注意**默认idea没有加载Terminal，需通过file-》设置-》plugins-》选中Terminal，重启idea才可使用
   4. 执行命令mvn clean package docker:build -Dpushimage (依次为清理->打包->构建镜像->上传到私有仓库)   
   5. 在服务器上通过命令查看镜像 docker images
   6. 启动容器 docker run -di --name=指定容器名 -p 端口号:指定端口号 镜像名:版本号
   

#### 4.持续集成 jenkins
>前提条件：代码托管到git或svn或码云等代码管理平台上
##### 1.Gogs git图形化界面
1. 下载gogs镜像     docker pull gogs/gogs
2. 创建容器     
   >docker run -d --name=gogs -p 10022:22 -p 3000:3000 -v /var/gogsdata:/data gogs/gogs
   
   **注意** 
   >1. 第一个-p是内部使用，第二个-p是对外访问的，
   >2. -v表示文件挂载, 表示把冒号后面的文件挂载到冒号前面指定的路径
3. 在外部浏览器访问http://服务器ip地址:3000
   >1. 选择数据库，可以选择Sqllite
   >2. 修改域名和应用URL，指定服务器ip地址，
   >3. 注册账号并登陆
   >4. 创建仓库(即项目) 
4. 上传代码
   >1. 在idea中的vcs菜单中选择启动版本控制合并，然后选择git
   >2. 选中项目右键选择Git->Repository->Remotes
   >3. 在URL中录入第三步创建仓库(项目)的地址，连接远程
   >4. 选中项目右键选择Git->add 添加
   >5. 选中项目右键选择Git->Commit Directory提交到本地
   >6. 选中项目右键选择Git->Repository->Push提交到远程，此处需录入远程的用户名和密码
   
##### 2.运用Jenkins实现持续集成
###### 1. Jenkins
1. Jenkins安装
   1. jdk安装 直接安装到宿主机上而不是创建容器
      >1. jdk8-linux.rpm上传到服务器(可以是虚拟机)
      >2. 执行安装命令   `rpm -ivh jdk8-linux.rpm`
   rpm方式安装的，其根目录为usr/java/jdk
   2. Jenkins的安装与启动
      >1. 下载或直接上传,执行命令    wget https://pkg.jenkins.io/redhat/jenkins-...noarch.rpm
      >2. 安装    rpm -ivh jenkins的rpm安装包
   3. 安装maven
      可以本地准备好上传或上传后在修改
      
      >1. 修改conf目录下的setting中指定仓库地址
2. 配置
   1. 通过vi /etc/sysconfig/jenkins打开配置文件
   2. 修改用户和端口 
      ```properties
      JENKINS_USER="root"
      JENKINS_PORT=指定端口
      ```
3. 启动服务  `systemctl start jenkins`
4. 浏览器访问 http://服务器ip地址:指定的端口
   >1. 此时需要登录密码，此密码在服务器/var/lib/jenkins/secrets/initialAdminPassword文件中
   >2. 安装插件maven和git 是必须的，可能不成功
   >3. 创建一个账户，登录进入
   >4. 对于不成功的插件可通过系统管理-》管理插件中进行安装
   >5. 系统管理-》全局工具配置,配置jdk，maven
   
 ###### 2. 持续集成
浏览器访问http://服务器ip地址:指定的端口并登陆
1. 创建任务

### 7.容器管理
#### 1. 容器管理工具Rancher
1.简介
   >1. 是开源的全栈化容器部署及管理工具

2.








### 8.容器监控 

 

 

 

​       

   









